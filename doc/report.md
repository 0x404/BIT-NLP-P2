# 自然语言理解初步大作业二

> 作者信息1：
>
> * 姓名：曾群鸿
> * 班级：07111905
> * 学号：1120192092
> * 联系电话：18959930736
> * 邮件地址：871206929@qq.com
>
> 作者信息2：
>
> * 姓名：舒敏宇
> * 班级：
> * 学号：
> * 联系电话：
> * 邮件地址：

**本项目为web项目，部署于http://www.0x404.tech，如无法访问请联系作者邮箱871206929@qq.com（或者QQ）**



## 核心思想与算法描述

文本摘要有两种实现方式，一种是基于生成的方式，通过使用RNN等神经网络进实现，另外一种是抽取的方式。

本次作业重点关注基于抽取式的文本自动摘要的实现，以及实现的算法——textrank。

pagerank算法应用于谷歌等搜索引擎中，通过网页链接的数量和质量来初略估计网页的重要性，从而对网页进行排名。textrank是基于pagerank算法的一种改进，它利用一篇文章内部词语共同出现的语义信息即可对一篇文章进行关键词抽取和关键句抽取，并且不需要依赖于语料库等训练数据。

下面从关键词抽取和关键句抽取两方面进行介绍。

### 关键词抽取

使用textrank进行关键词抽取的核心思想为利用词之间的相邻关系来构建一个词网络，然后使用pagerank的方式进行迭代计算，得到每个节点的权值，一个节点的权值越高其重要程度越高，故而得到关键词。

但可以发现，一个句子中有一些常用的词，如“的”、“了”等出现频率非常高，这类词也被称为停用词，尽管出现频率高但不可能作为关键词，所以一个句子总是将停用词去掉后再进行关键词的抽取。

具体算法描述如下：

1. 给定输入句子$input=w_1w_2w_3...w_n$

2. 使用jieba进行分词，得到输入句子的词序列$inputSeq=[w_1,w_2,...,w_n]$

3. 加载停用词表，对$inputSeq$中的词进行过滤，经过停用词表过滤后的词序列为$wordSeq=[w_1,w_2,...,w_k]$。

   由于在此步骤中主要操作可以描述为：查询一个给定词$w$是否在一个词典中，所以使用了字典树数据结构来进行优化，避免了一次查询需要扫描一次词典的低效操作。

4. 计算邻接矩阵$T_{i,j}$，其中$T_{i,j}=k$表示从词$i$转移到词$j$的次数为$k$，为了定义转移使用了一个共现窗口来定义，窗口的大小默认定义为$3$。那么如果$|i-j|\le 3$，则$w_i$可以转移到$w_j$且$w_j$也可以转移到$w_i$，也就是说$T$是一个对称矩阵。

   在完成转移次数的计算后，对$T$进行归一化计算$T_{i,j}=\frac{T_{i,j}}{\sum_{k=1}^{n}T_{i,k}}$，即$T_{i,j}$为从$w_i$到$w_j$转移的概率。

5. 通过如下公式对词网络进行迭代计算，直到收敛：
   $$
   val_i=(1-d)+d\times \sum_{j\in in(i)}\frac{W_{j,i}\times val_j}{\sum_{k\in out(j)W_{j,k}}}
   \\=(1-d)+d\times \sum_{j\in in(i)}T_{i,j}val_j
   $$
   为了判断收敛，我通过计算迭代前后两个$rank$相邻的二范数之差，如果两者之差小于$0.0001$则认为$rank$向量收敛

6. 根据$rank$向量，选择$rank$值最大的几个词当作本篇文章的关键词。

### 关键句抽取

基于textrank的关键句抽取核心思想与上述关键词抽取基本相同，在关键句抽取中以句子作为单位，而不是以此作为单位。

此时，

## 实验结果及分析



## 分工情况
